{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b4f623-c66c-46c0-8305-e93e7688d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[toy-text] in /home/oppenheimer/.local/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/oppenheimer/.local/lib/python3.10/site-packages (from gymnasium[toy-text]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/oppenheimer/.local/lib/python3.10/site-packages (from gymnasium[toy-text]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/oppenheimer/.local/lib/python3.10/site-packages (from gymnasium[toy-text]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/oppenheimer/.local/lib/python3.10/site-packages (from gymnasium[toy-text]) (0.0.4)\n",
      "Collecting pygame>=2.1.3 (from gymnasium[toy-text])\n",
      "  Downloading pygame-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading pygame-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m840.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium[toy-text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa3dbe1-fa6f-479f-91a4-8b18a302d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88bc04-c5ed-4814-a0a0-040ff1dbf924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8c6332-dd48-401f-ba9f-235a502a0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f92e16b-367c-4cac-a7c7-e22691c19d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aecb94-48e1-42e4-a005-233d87578e53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e30531-2cfc-4c82-87d6-d83048f5d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Discretization function\n",
    "def discretize_state(state, bins):\n",
    "    position, velocity = state\n",
    "    position_bin = np.digitize(position, bins['position']) - 1\n",
    "    velocity_bin = np.digitize(velocity, bins['velocity']) - 1\n",
    "    return position_bin, velocity_bin\n",
    "\n",
    "# Create bins for discretization\n",
    "def create_bins(num_bins):\n",
    "    position_bins = np.linspace(-1.2, 0.6, num_bins)\n",
    "    velocity_bins = np.linspace(-0.07, 0.07, num_bins)\n",
    "    return {'position': position_bins, 'velocity': velocity_bins}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2c6235-e51c-47b5-980d-1e1a77ee8b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': array([-1.2, -1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6]),\n",
       " 'velocity': array([-0.07      , -0.05444444, -0.03888889, -0.02333333, -0.00777778,\n",
       "         0.00777778,  0.02333333,  0.03888889,  0.05444444,  0.07      ])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    num_bins = 10\n",
    "    bins = create_bins(num_bins)\n",
    "bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d0bb837-528e-4176-915c-2e0f0c86b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(env, policy, value_function, bins, gamma):\n",
    "    value_function = np.zeros((len(bins['position']), len(bins['velocity'])))\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for position_bin in range(len(bins['position'])-1):\n",
    "            for velocity_bin in range(len(bins['velocity'])-1):\n",
    "                state = (position_bin, velocity_bin)\n",
    "                v = 0\n",
    "                for action in range(env.action_space.n):\n",
    "                    state=env.reset()\n",
    "                    next_state,reward,terminated,truncated,info=env.step(action)\n",
    "                    next_position_bin, next_velocity_bin = discretize_state(next_state, bins)\n",
    "                    v += policy[position_bin, velocity_bin,action] * (reward + gamma * value_function[next_position_bin,next_velocity_bin])\n",
    "                value_function[position_bin, velocity_bin] = v\n",
    "                delta = max(delta, abs(v - value_function[position_bin, velocity_bin]))\n",
    "        if delta < 1e-5:\n",
    "            break\n",
    "    return value_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37da3acf-a182-48e1-894e-a0c137158112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def policy_improvement(env,value_function,policy,bins,gamma):\n",
    "    \n",
    "    policy_stable = False\n",
    "    while not policy_stable:\n",
    "        policy_stable = True\n",
    "           \n",
    "        for position_bin in range(len(bins['position'])-1):\n",
    "            for velocity_bin in range(len(bins['velocity'])-1):\n",
    "                state = (position_bin, velocity_bin)\n",
    "                old_action = np.argmax(policy[state])\n",
    "                action_values = []\n",
    "                for action in range(env.action_space.n):\n",
    "                    env.reset()\n",
    "                    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                    next_position_bin, next_velocity_bin = discretize_state(next_state, bins)\n",
    "                    action_values.append(reward + gamma * value_function[next_position_bin][next_velocity_bin])\n",
    "                new_action = np.argmax(action_values)\n",
    "                policy[state] = np.eye(env.action_space.n)[new_action]\n",
    "                if old_action != new_action:\n",
    "                    policy_stable = False\n",
    "    \n",
    "    return policy,policy_stable \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eda9dd52-1746-48f2-8a31-d90381d6f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def policy_iteration(env, bins, gamma=0.9):\n",
    "    # Initialize value function and policy\n",
    "    value_function = np.zeros((len(bins['position'])-1, len(bins['velocity'])-1))\n",
    "    policy = np.ones((len(bins['position'])-1, len(bins['velocity'])-1, env.action_space.n)) / env.action_space.n\n",
    "    while True:\n",
    "        # Policy Evaluation\n",
    "        value_function = policy_eval(env, policy, value_function, bins, gamma)\n",
    "        \n",
    "        # Policy Improvement\n",
    "        policy, policy_stable = policy_improvement(env, value_function, policy, bins, gamma)\n",
    "        \n",
    "        if policy_stable:\n",
    "            break\n",
    "    \n",
    "    return policy, value_function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d286e581-e981-4115-9b29-7af263a066d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.99  # Discount factor\n",
    "policy, value_function = policy_iteration(env, bins, gamma)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116640c-d99f-482b-9261-f99b6d3be638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
